## homework 0: 2018.02.24: sml-group-study starts
- Run through the current code (Google Colab or your own setup)

## homework 1: 2018.03.03
*Homework 1 (Due next week)*
We will modify the code to run it on different images we choose. Choose what you want to classify (i.e. apples vs pears, darth vader vs luke skywalker)
- Download two different types of 50-100 (i.e. 50 apples 50 pears)
- Try modifying the code from before to work on this data

You can use this chrome extension to download images.

https://chrome.google.com/webstore/detail/image-downloader/cnpniohnfphhjihaiiggeabnkjhpaldj

To use, just go on Google Image search, type in a query i.e. Darth Vader, click on the extension and select the images you want to save (that are actually of Darth Vader).

We will be going over some theory *next* Sat and hints on how to solve the task. 
At the end of next week we'll be discussing the different results groups found and any insights of looking at different types of images.

Lastly.... we will be sending a survey for tips and advice how to improve for the future lessons, please let us know how we can improve
chrome.google.com
Image Downloader
Browse and download images on a web page.


## homework 2: 2018.03.10
Fast AI is amazing and easy to use on your own data source. This weeks *Homework (HW 2)* however is to try apply our *Fast ai model from homework 1* to a real world data source on Kaggle and see how you score on the leaderboard. You will need a Kaggle account set up and accept the competition rules in order to download the data set.

Recommended sources for this week are:

- https://www.kaggle.com/c/dog-breed-identification

- https://www.kaggle.com/c/whale-categorization-playground/data

- https://www.kaggle.com/c/plant-seedlings-classification

Jeremy has provided his solution file for the dog breed classification in the "DL1" folder called "Kaggle - Dogbreeds" so refer to this Python notebook if you need extra help with this weeks home work.
kaggle.com
Dog Breed Identification
Determine the breed of a dog in an image
kaggle.com
Humpback Whale Identification Challenge
Can you identify a whale by the picture of its fluke?
kaggle.com
Plant Seedlings Classification
Determine the species of a seedling from an image


## homework 3: 2018.03.17
This week's homework will be be applying what you have learned onto other Kaggle datasets to do a *prediction task*. We've picked two datasets that has some real world applications for you to apply your skills to

*Used Car Sales*
https://www.kaggle.com/orgesleka/used-cars-database

*Deaths in the United States*
https://www.kaggle.com/cdc/mortality/data

Let us know how you get along and don't be afraid to ask any questions! (edited)
kaggle.com
Used cars database
Over 370,000 used cars scraped from Ebay Kleinanzeigen
kaggle.com
Death in the United States
Learn more about the leading causes of death from 2005-2015


## homework 4: 2018.03.24
This weeks homework, ( *homework 4* ) is arguably one of the *most challenging*, but *useful yet*! In order to “look under the hood” as it were & learn usable skills you could mention to potential employers - for this week we would like you to walk through the *“Deep Learning with PyTorch: A 60 minute Blitz”*  tutorial from the official Pytorch documentation which is located here:

http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html

*Please attempt to get through the following steps of the tutorial*:

*1. What is PyTorch?*
*2. Autograd automatic differentiation*
*3. Neural Networks*
*4. Training a Classifier.*

For the more *advanced students* in the class & for those of you who complete the above,
once you have reached the "where do I go next” section in the above, we would like you like you to complete the PyTorch NLP  tutorial to build a basic sentiment analysis classifier:

http://pytorch.org/tutorials/beginner/deep_learning_nlp_tutorial.html

For the following easy dataset from either IMDB, Yelp or Amazon data:

https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip


## homework 5: 2019.03.31 : Easter holiday


## homework 5-6: 2018.04.07

Hi guys,
#### This weeks homework ( *homework 5* ) is to *choose three topics* from the fast.ai course *that you feel the most unsure about* and research and study them - to reinforce your knowledge-  in your own time this week. If you uncover any handy resources/ tutorials/ videos on the internet, please feel free to share them on the # tools channel - so that others can learn from your findings too!

Example Topics include:

1. mathematical “logs” ( and log loss)
2. Test Time Augmentation (TTA)
3. Embeddings
4. Matrix Factorization, "latent factors” etc
5. How enumeration works in python
6. Numpy Broadcasting
7. Jacobian / Hessian Matrices
8. The Chain Rule
9. Stochastic Gradient Descent (SGD)
10. Momentum (for SGD)
11. The ADAM optimiser ( & ADAMw)
12.  *any other topics you may have had trouble with!*

In on our final session on Saturday the 7th of April, *we will be asking one team member from each team to please present their findings* on ONE topic that you researched.

Enjoy the easter break & see you all for the last  faster.ai session soon! (edited)

#### additional homework
Hi everyone,
*Part 1: Theory*

To get a solid understanding of the underlying principles of how a Recurrent Neural Network works - for the final homework session (*homework 6*) we would like you to *read through Andrej Karpathy’s excellent RNN tutorial*, Andrej’s tutorial is located here:

https://karpathy.github.io/2015/05/21/rnn-effectiveness/

*Part 2: Practical*

Once you have understood the under-lying theory, we would like you to *walk through the official Pytorch RNN tutorial* by copying the cell blocks into a Jupyter notebook and understanding each step as you go. The first Pytorch RNN tutorial can be located here:

http://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html

*Part 3: Generation!*

Once you have completed the above practical example, we would like you to complete the final section of the homework by following final RNN Pytorch tutorial *to do text generation!!!* The final tutorial can be located here:

http://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html

Instead of generating names we would like you to input some other corpus of text input & see what awesome generated outputs you can come up with,  try inputing some of the following to see what RNNs are capable of:

-cooking recipes
-Holy book text
-raw code
-wikipedia
-or anything else you can think of!

*We will be asking one team at random to present* on the above task, so GL & HF & see you at the last study group session this Saturday the 7th of April! (edited)
karpathy.github.io
The Unreasonable Effectiveness of Recurrent Neural Networks
Musings of a Computer Scientist.
